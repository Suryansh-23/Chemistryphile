{"ast":null,"code":"var _jsxFileName = \"F:\\\\JavaScript\\\\Projects\\\\chemistryphile\\\\src\\\\components\\\\SpeechRecog.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState } from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst Dictaphone1 = () => {\n  _s();\n\n  const [message, setMessage] = useState('');\n  const commands = [{\n    command: 'reset',\n    callback: () => resetTranscript()\n  }, {\n    command: 'shut up',\n    callback: () => setMessage('I wasn\\'t talking.')\n  }, {\n    command: 'Hello',\n    callback: () => setMessage('Hi there!')\n  }];\n  const {\n    transcript,\n    interimTranscript,\n    finalTranscript,\n    resetTranscript,\n    listening\n  } = useSpeechRecognition({\n    commands\n  });\n  useEffect(() => {\n    if (finalTranscript !== '') {\n      console.log('Got final result:', finalTranscript);\n    }\n  }, [interimTranscript, finalTranscript]);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    console.log('Your browser does not support speech recognition software! Try Chrome desktop, maybe?');\n  }\n\n  const listenContinuously = () => {\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: 'en-GB'\n    });\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"span\", {\n        children: [\"listening:\", ' ', listening ? 'on' : 'off']\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 49,\n        columnNumber: 8\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: [/*#__PURE__*/_jsxDEV(\"button\", {\n          type: \"button\",\n          onClick: resetTranscript,\n          children: \"Reset\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 55,\n          columnNumber: 10\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          type: \"button\",\n          onClick: listenContinuously,\n          children: \"Listen\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 56,\n          columnNumber: 10\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          type: \"button\",\n          onClick: SpeechRecognition.stopListening,\n          children: \"Stop\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 57,\n          columnNumber: 10\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 54,\n        columnNumber: 8\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 48,\n      columnNumber: 6\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: message\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 60,\n      columnNumber: 6\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: /*#__PURE__*/_jsxDEV(\"span\", {\n        children: transcript\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 8\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 6\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 47,\n    columnNumber: 4\n  }, this);\n};\n\n_s(Dictaphone1, \"BGYWCeP7cCZQ6XbDILl3QFNkw80=\", false, function () {\n  return [useSpeechRecognition];\n});\n\n_c = Dictaphone1;\nexport default Dictaphone1;\n\nvar _c;\n\n$RefreshReg$(_c, \"Dictaphone1\");","map":{"version":3,"sources":["F:/JavaScript/Projects/chemistryphile/src/components/SpeechRecog.js"],"names":["React","useEffect","useState","SpeechRecognition","useSpeechRecognition","Dictaphone1","message","setMessage","commands","command","callback","resetTranscript","transcript","interimTranscript","finalTranscript","listening","console","log","browserSupportsSpeechRecognition","listenContinuously","startListening","continuous","language","stopListening"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,QAA3B,QAA2C,OAA3C;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;AAEA,MAAMC,WAAW,GAAG,MAAM;AAAA;;AACzB,QAAM,CAACC,OAAD,EAAUC,UAAV,IAAwBL,QAAQ,CAAC,EAAD,CAAtC;AACA,QAAMM,QAAQ,GAAG,CACf;AACEC,IAAAA,OAAO,EAAE,OADX;AAEEC,IAAAA,QAAQ,EAAE,MAAMC,eAAe;AAFjC,GADe,EAKf;AACEF,IAAAA,OAAO,EAAE,SADX;AAEEC,IAAAA,QAAQ,EAAE,MAAMH,UAAU,CAAC,oBAAD;AAF5B,GALe,EASf;AACEE,IAAAA,OAAO,EAAE,OADX;AAEEC,IAAAA,QAAQ,EAAE,MAAMH,UAAU,CAAC,WAAD;AAF5B,GATe,CAAjB;AAcA,QAAM;AACJK,IAAAA,UADI;AAEJC,IAAAA,iBAFI;AAGJC,IAAAA,eAHI;AAIJH,IAAAA,eAJI;AAKJI,IAAAA;AALI,MAMFX,oBAAoB,CAAC;AAAEI,IAAAA;AAAF,GAAD,CANxB;AAQAP,EAAAA,SAAS,CAAC,MAAM;AACd,QAAIa,eAAe,KAAK,EAAxB,EAA4B;AAC1BE,MAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ,EAAiCH,eAAjC;AACD;AACF,GAJQ,EAIN,CAACD,iBAAD,EAAoBC,eAApB,CAJM,CAAT;;AAKA,MAAI,CAACX,iBAAiB,CAACe,gCAAlB,EAAL,EAA2D;AACzD,WAAO,IAAP;AACD;;AAED,MAAI,CAACf,iBAAiB,CAACe,gCAAlB,EAAL,EAA2D;AACzDF,IAAAA,OAAO,CAACC,GAAR,CAAY,uFAAZ;AACD;;AACD,QAAME,kBAAkB,GAAG,MAAM;AAC/BhB,IAAAA,iBAAiB,CAACiB,cAAlB,CAAiC;AAC/BC,MAAAA,UAAU,EAAE,IADmB;AAE/BC,MAAAA,QAAQ,EAAE;AAFqB,KAAjC;AAID,GALD;;AAMA,sBACE;AAAA,4BACE;AAAA,8BACE;AAAA,iCAEG,GAFH,EAGGP,SAAS,GAAG,IAAH,GAAU,KAHtB;AAAA;AAAA;AAAA;AAAA;AAAA,cADF,eAME;AAAA,gCACE;AAAQ,UAAA,IAAI,EAAC,QAAb;AAAsB,UAAA,OAAO,EAAEJ,eAA/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,eAEE;AAAQ,UAAA,IAAI,EAAC,QAAb;AAAsB,UAAA,OAAO,EAAEQ,kBAA/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAFF,eAGE;AAAQ,UAAA,IAAI,EAAC,QAAb;AAAsB,UAAA,OAAO,EAAEhB,iBAAiB,CAACoB,aAAjD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAHF;AAAA;AAAA;AAAA;AAAA;AAAA,cANF;AAAA;AAAA;AAAA;AAAA;AAAA,YADF,eAaE;AAAA,gBACGjB;AADH;AAAA;AAAA;AAAA;AAAA,YAbF,eAgBE;AAAA,6BACE;AAAA,kBAAOM;AAAP;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,YAhBF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAsBA,CAhED;;GAAMP,W;UAsBDD,oB;;;KAtBCC,W;AAkEN,eAAeA,WAAf","sourcesContent":["import React, { useEffect, useState } from 'react';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\nconst Dictaphone1 = () => {\r\n const [message, setMessage] = useState('');\r\n const commands = [\r\n   {\r\n     command: 'reset',\r\n     callback: () => resetTranscript()\r\n   },\r\n   {\r\n     command: 'shut up',\r\n     callback: () => setMessage('I wasn\\'t talking.')\r\n   },\r\n   {\r\n     command: 'Hello',\r\n     callback: () => setMessage('Hi there!')\r\n   },\r\n ]\r\n const {\r\n   transcript,\r\n   interimTranscript,\r\n   finalTranscript,\r\n   resetTranscript,\r\n   listening,\r\n } = useSpeechRecognition({ commands });\r\n\r\n useEffect(() => {\r\n   if (finalTranscript !== '') {\r\n     console.log('Got final result:', finalTranscript);\r\n   }\r\n }, [interimTranscript, finalTranscript]);\r\n if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\r\n   return null;\r\n }\r\n\r\n if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\r\n   console.log('Your browser does not support speech recognition software! Try Chrome desktop, maybe?');\r\n }\r\n const listenContinuously = () => {\r\n   SpeechRecognition.startListening({\r\n     continuous: true,\r\n     language: 'en-GB',\r\n   });\r\n };\r\n return (\r\n   <div>\r\n     <div>\r\n       <span>\r\n         listening:\r\n         {' '}\r\n         {listening ? 'on' : 'off'}\r\n       </span>\r\n       <div>\r\n         <button type=\"button\" onClick={resetTranscript}>Reset</button>\r\n         <button type=\"button\" onClick={listenContinuously}>Listen</button>\r\n         <button type=\"button\" onClick={SpeechRecognition.stopListening}>Stop</button>\r\n       </div>\r\n     </div>\r\n     <div>\r\n       {message}\r\n     </div>\r\n     <div>\r\n       <span>{transcript}</span>\r\n     </div>\r\n   </div>\r\n );\r\n};\r\n\r\nexport default Dictaphone1;\r\n"]},"metadata":{},"sourceType":"module"}